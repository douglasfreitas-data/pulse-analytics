# üè∑Ô∏è Guia de Fine-Tuning e Anota√ß√£o Manual

Este documento explica como refinar o modelo de detec√ß√£o de picos PPG usando seus pr√≥prios dados, mesmo sem ter um ECG de refer√™ncia.

---

## 1. Por que Fine-Tuning?

O modelo treinado no MIMIC-II (pacientes de UTI, idosos) pode n√£o funcionar perfeitamente nos seus dados (jovem, saud√°vel, sensor diferente).

**Fine-tuning** = pegar um modelo pr√©-treinado e ajustar com poucos dados do seu contexto.

```
Modelo MIMIC (gen√©rico) ‚Üí + Seus dados anotados ‚Üí Modelo Adaptado (espec√≠fico)
```

---

## 2. O Problema: "N√£o tenho ECG para rotular"

No MIMIC, usamos o ECG como gabarito. Nos seus dados, voc√™ s√≥ tem PPG.

**Solu√ß√£o:** O modelo J√Å sabe detectar picos (aprendeu no MIMIC). Voc√™ s√≥ precisa **corrigir os erros**.

---

## 3. Fluxo de Anota√ß√£o Semi-Autom√°tica

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PASSO 1: Modelo prediz nos seus dados                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Seu PPG ‚Üí Modelo MIMIC ‚Üí Picos preditos: [127, 254, 389]    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PASSO 2: Voc√™ verifica visualmente                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Olha o gr√°fico e identifica:                                ‚îÇ
‚îÇ  ‚úì 127 ‚Üí Correto                                             ‚îÇ
‚îÇ  ‚úì 254 ‚Üí Correto                                             ‚îÇ
‚îÇ  ‚úó 389 ‚Üí Errado! Deveria ser 395                             ‚îÇ
‚îÇ  ‚úó Faltou o pico em 520                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PASSO 3: Criar ground truth corrigido                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Picos corrigidos: [127, 254, 395, 520]                      ‚îÇ
‚îÇ  Salvar como CSV ou array numpy                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PASSO 4: Fine-tuning                                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Retreinar modelo com learning rate baixo (1e-5)             ‚îÇ
‚îÇ  Poucas √©pocas (5-10)                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 4. M√©todos de Anota√ß√£o Manual

### M√©todo 1: Corre√ß√£o em CSV (Mais Simples)

1. Rodar modelo e salvar predi√ß√µes:
```python
predicted_peaks = model.predict(ppg)
np.savetxt('peaks_predicted.csv', predicted_peaks, delimiter=',')
```

2. Abrir CSV no Excel/LibreCalc
3. Comparar com gr√°fico e editar valores errados
4. Salvar como `peaks_corrected.csv`

**Pr√≥s:** Simples, n√£o precisa de c√≥digo extra
**Contras:** Trabalhoso, propenso a erros

---

### M√©todo 2: Clique Interativo no Gr√°fico (Recomendado)

Widget Python onde voc√™ clica diretamente nos picos:

```python
import matplotlib.pyplot as plt

class PeakAnnotator:
    """Ferramenta para anotar picos clicando no gr√°fico."""
    
    def __init__(self, ppg, fs=125):
        self.ppg = ppg
        self.fs = fs
        self.peaks = []
        self.fig, self.ax = plt.subplots(figsize=(16, 4))
        
        # Plotar sinal
        t = np.arange(len(ppg)) / fs
        self.ax.plot(t, ppg, 'purple', linewidth=0.8)
        self.ax.set_xlabel('Tempo (s)')
        self.ax.set_ylabel('PPG')
        self.ax.set_title('Clique nos PICOS para marcar | Clique direito para remover √∫ltimo')
        self.ax.grid(True, alpha=0.3)
        
        # Conectar eventos
        self.fig.canvas.mpl_connect('button_press_event', self.on_click)
        self.markers = []
        
    def on_click(self, event):
        if event.inaxes != self.ax:
            return
            
        if event.button == 1:  # Clique esquerdo = adicionar
            x_sample = int(event.xdata * self.fs)
            self.peaks.append(x_sample)
            marker = self.ax.axvline(event.xdata, color='red', alpha=0.6, linewidth=2)
            self.markers.append(marker)
            
        elif event.button == 3:  # Clique direito = remover √∫ltimo
            if self.peaks:
                self.peaks.pop()
                self.markers[-1].remove()
                self.markers.pop()
                
        self.fig.canvas.draw()
        
    def get_peaks(self):
        return sorted(self.peaks)
    
    def save(self, filepath):
        np.savetxt(filepath, self.get_peaks(), fmt='%d')
        print(f"Salvos {len(self.peaks)} picos em {filepath}")

# Uso:
annotator = PeakAnnotator(seu_ppg, fs=125)
plt.show()

# Depois de anotar:
annotator.save('meus_picos_anotados.csv')
```

**Pr√≥s:** Visual, intuitivo, r√°pido
**Contras:** Precisa rodar em ambiente com GUI (n√£o funciona em server)

---

### M√©todo 3: Corre√ß√£o de Predi√ß√£o Existente (Mais R√°pido)

Se o modelo j√° acerta ~90%, voc√™ s√≥ corrige os erros:

```python
class PeakCorrector:
    """Corrige predi√ß√µes existentes do modelo."""
    
    def __init__(self, ppg, predicted_peaks, fs=125):
        self.ppg = ppg
        self.peaks = list(predicted_peaks)
        self.fs = fs
        self.fig, self.ax = plt.subplots(figsize=(16, 4))
        
        t = np.arange(len(ppg)) / fs
        self.ax.plot(t, ppg, 'purple', linewidth=0.8)
        
        # Mostrar picos preditos
        self.markers = []
        for peak in self.peaks:
            marker = self.ax.axvline(peak/fs, color='green', alpha=0.5)
            self.markers.append(marker)
        
        self.ax.set_title('Verde=predito | Clique esq=adicionar | Clique dir=remover mais pr√≥ximo')
        
        self.fig.canvas.mpl_connect('button_press_event', self.on_click)
        
    def on_click(self, event):
        if event.inaxes != self.ax:
            return
            
        x_sample = int(event.xdata * self.fs)
        
        if event.button == 1:  # Adicionar pico
            self.peaks.append(x_sample)
            marker = self.ax.axvline(event.xdata, color='red', alpha=0.8)
            self.markers.append(marker)
            
        elif event.button == 3:  # Remover pico mais pr√≥ximo
            if self.peaks:
                closest_idx = np.argmin(np.abs(np.array(self.peaks) - x_sample))
                self.peaks.pop(closest_idx)
                self.markers[closest_idx].remove()
                self.markers.pop(closest_idx)
        
        self.fig.canvas.draw()
```

**Pr√≥s:** Muito r√°pido se modelo j√° √© bom
**Contras:** Pode perder picos se n√£o verificar tudo

---

### M√©todo 4: Active Learning (Avan√ßado)

O modelo indica regi√µes de **baixa confian√ßa**, voc√™ prioriza anotar essas:

```python
# Modelo retorna probabilidades por sample
probs = model.predict_proba(ppg)  # Shape: (n_samples,)

# Encontrar regi√µes incertas
uncertain_mask = (probs > 0.3) & (probs < 0.7)
uncertain_regions = np.where(uncertain_mask)[0]

# Mostrar s√≥ essas regi√µes pro humano
print(f"Regi√µes incertas: {len(uncertain_regions)} samples para revisar")
```

**Pr√≥s:** Maximiza valor da anota√ß√£o humana
**Contras:** Mais complexo de implementar

---

## 5. Quanto Anotar?

| Quantidade | Qualidade esperada | Tempo estimado |
|------------|-------------------|----------------|
| 30 segundos (~40 picos) | Teste b√°sico | 5 min |
| 2 minutos (~150 picos) | Fine-tuning m√≠nimo | 15 min |
| 5 minutos (~400 picos) | Bom fine-tuning | 30 min |
| 10 minutos | Excelente | 1 hora |

**Dica:** Anote sess√µes variadas (repouso, p√≥s-esfor√ßo, respira√ß√£o lenta).

---

## 6. C√≥digo de Fine-Tuning

Depois de anotar:

```python
def fine_tune_model(model, ppg, corrected_peaks, epochs=10, lr=1e-5):
    """
    Fine-tune o modelo com seus dados anotados.
    
    Args:
        model: Modelo pr√©-treinado (Performer)
        ppg: Sinal PPG normalizado
        corrected_peaks: Lista de √≠ndices dos picos corretos
        epochs: N√∫mero de √©pocas (poucos!)
        lr: Learning rate (baixo!)
    """
    # Criar labels a partir dos picos
    labels = np.zeros(len(ppg))
    for peak in corrected_peaks:
        for offset in range(-3, 4):  # ¬±3 samples
            if 0 <= peak + offset < len(labels):
                labels[peak + offset] = 1
    
    # Criar janelas
    X, y = create_windows(ppg, labels, window_size=500, stride=125)
    
    # Fine-tuning com learning rate baixo
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    
    for epoch in range(epochs):
        model.train()
        # ... loop de treino normal ...
    
    return model
```

**Regras de ouro:**
- Learning rate **10-100x menor** que no pr√©-treino
- Poucas √©pocas (5-15) para n√£o "esquecer" o MIMIC
- Validar em dados que voc√™ N√ÉO anotou

---

## 7. Resumo do Fluxo

```mermaid
flowchart LR
    A[PPG Seu] --> B[Modelo MIMIC]
    B --> C{Predi√ß√µes}
    C --> D[Verificar Visual]
    D -->|Erros?| E[Corrigir Manual]
    D -->|OK?| F[Usar direto]
    E --> G[Fine-tune]
    G --> H[Modelo Adaptado]
```

---

> **Pr√≥ximo passo:** Rodar o modelo no seu PPG do mindinho e ver quantos erros ele comete. Se <10%, talvez nem precise de fine-tuning!
