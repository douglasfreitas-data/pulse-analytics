# V3 - DECISÃ•ES DE ARQUITETURA

> **Objetivo:** Documentar as dÃºvidas levantadas durante o planejamento e como foram resolvidas, demonstrando pensamento crÃ­tico sobre viabilidade tÃ©cnica e econÃ´mica do projeto.

---

## ğŸ“‹ Ãndice de DecisÃµes

1. [Nomenclatura UX para os Modos de MediÃ§Ã£o](#nomenclatura)
2. [OrganizaÃ§Ã£o das Tabelas no Banco](#tabelas)
3. [EstratÃ©gia de Treinamento (DecimaÃ§Ã£o + Transfer Learning)](#treinamento)
4. [PriorizaÃ§Ã£o do Desenvolvimento](#priorizacao)

---

## 1. Nomenclatura UX para os Modos de MediÃ§Ã£o {#nomenclatura}

### â“ DÃºvida Original

> "Criar rotina no app de coleta das duas fases, mas nÃ£o com nome de fase e sim com nomes UX melhores"

### ğŸ¤” AnÃ¡lise

O termo "Fase 1" e "Fase 2" sÃ£o tÃ©cnicos e nÃ£o comunicam valor ao usuÃ¡rio final. Precisamos de nomes que:
- Comuniquem o **benefÃ­cio** da mediÃ§Ã£o
- Sejam **intuitivos** e nÃ£o tÃ©cnicos
- Reflitam a **frequÃªncia de uso** esperada

### âœ… DecisÃ£o Final

| Interno (TÃ©cnico) | Nome UX | DescriÃ§Ã£o para UsuÃ¡rio | FrequÃªncia |
|-------------------|---------|------------------------|------------|
| **Fase 2** (200 Hz) | **"Meu Dia"** | Avalia seu estresse, recuperaÃ§Ã£o e equilÃ­brio do sistema nervoso | DiÃ¡ria |
| **Fase 1+2** (757 Hz + 200 Hz) | **"Check-up Completo"** | AnÃ¡lise detalhada da saÃºde vascular + estresse | Semanal/Mensal |

### ğŸ’¡ Alternativas Consideradas

| OpÃ§Ã£o | Fase 2 | Fase 1+2 | Motivo de RejeiÃ§Ã£o |
|-------|--------|----------|---------------------|
| A | "MediÃ§Ã£o RÃ¡pida" | "MediÃ§Ã£o Completa" | Muito genÃ©rico |
| B | "HRV Check" | "Health Check" | Usa sigla tÃ©cnica |
| C | "Daily Pulse" | "Deep Scan" | InglÃªs (pÃºblico BR) |
| **D (escolhido)** | **"Meu Dia"** | **"Check-up Completo"** | Claro, brasileiro, orientado a benefÃ­cio |

### ğŸ“± Comportamento no App

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PULSE ANALYTICS               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚         ğŸ’š MEU DIA              â”‚   â”‚
â”‚   â”‚    Estresse & RecuperaÃ§Ã£o       â”‚   â”‚
â”‚   â”‚         â±ï¸ 5 minutos            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚     ğŸ”¬ CHECK-UP COMPLETO        â”‚   â”‚
â”‚   â”‚    SaÃºde Vascular + Estresse    â”‚   â”‚
â”‚   â”‚         â±ï¸ 6 minutos            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. OrganizaÃ§Ã£o das Tabelas no Banco {#tabelas}

### â“ DÃºvida Original

> "Teremos uma nova tabela? Separamos uma para 757Hz e outra para 200Hz? Devemos reorganizar as tabelas?"

### ğŸ¤” AnÃ¡lise

**OpÃ§Ã£o A: Tabelas Separadas por FrequÃªncia**
```sql
-- Tabela para 200 Hz
CREATE TABLE daily_measurements (...);

-- Tabela para 757 Hz
CREATE TABLE checkup_morphology (...);
```

**PrÃ³s:**
- Schemas especÃ­ficos para cada tipo de dado
- Queries mais simples

**Contras:**
- DuplicaÃ§Ã£o de metadados (user, device, tags)
- Dificuldade para relacionar mediÃ§Ãµes do mesmo dia
- Mais complexidade na manutenÃ§Ã£o

---

**OpÃ§Ã£o B: Tabela Ãšnica com Session Type**
```sql
CREATE TABLE measurements (
    measurement_type TEXT, -- 'daily' ou 'checkup'
    sampling_rate_hz INT,
    -- campos comuns...
);
```

**PrÃ³s:**
- Simples
- HistÃ³rico unificado

**Contras:**
- Muitos campos NULL (campos de morfologia vazios em 'daily')
- DifÃ­cil escalar se os schemas divergirem muito

---

**OpÃ§Ã£o C: Tabela Base + Tabelas EspecÃ­ficas (escolhida)**
```sql
-- Tabela base com metadados comuns
CREATE TABLE sessions (...);

-- Tabela especÃ­fica para dados de HRV
CREATE TABLE hrv_data (...);

-- Tabela especÃ­fica para dados de morfologia
CREATE TABLE morphology_data (...);
```

**PrÃ³s:**
- NormalizaÃ§Ã£o adequada
- Cada tipo de dado tem seu schema otimizado
- FÃ¡cil adicionar novos tipos de mediÃ§Ã£o
- Permite anÃ¡lises cruzadas via session_id

**Contras:**
- JOINs necessÃ¡rios para relatÃ³rios completos

### âœ… DecisÃ£o Final

**OpÃ§Ã£o C: Modelo Relacional Normalizado**

```sql
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           SESSIONS                                  â”‚
â”‚  (Metadados comuns: user, device, timestamp, tags)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  id | user_name | created_at | device_id | session_type | tags    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     HRV_DATA        â”‚  â”‚  MORPHOLOGY_DATA    â”‚
â”‚  (session_id FK)    â”‚  â”‚  (session_id FK)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - sampling_rate     â”‚  â”‚ - sampling_rate     â”‚
â”‚ - duration_sec      â”‚  â”‚ - duration_sec      â”‚
â”‚ - rr_intervals      â”‚  â”‚ - ir_waveform       â”‚
â”‚ - sdnn, rmssd...    â”‚  â”‚ - red_waveform      â”‚
â”‚ - lf, hf, lf_hf     â”‚  â”‚ - ri, si, lvet      â”‚
â”‚                     â”‚  â”‚ - agi, vascular_age â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Š Schema SQL Proposto

```sql
-- Tabela principal de sessÃµes
CREATE TABLE sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    created_at TIMESTAMPTZ DEFAULT NOW(),
    
    -- IdentificaÃ§Ã£o
    device_id TEXT DEFAULT 'ESP32-S3',
    user_name TEXT DEFAULT 'Visitante',
    
    -- Tipo de sessÃ£o
    session_type TEXT NOT NULL, -- 'daily' ou 'checkup'
    
    -- Demografia
    user_age SMALLINT,
    user_gender TEXT,
    
    -- Contexto
    tags TEXT[]
);

-- Dados HRV (mediÃ§Ã£o diÃ¡ria)
CREATE TABLE hrv_data (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,
    
    -- ParÃ¢metros de coleta
    sampling_rate_hz INT DEFAULT 200,
    duration_sec INT DEFAULT 300, -- 5 minutos
    
    -- Waveform (opcional, para debug/treinamento)
    ir_waveform JSONB,
    
    -- Intervalos RR
    rr_intervals_ms JSONB,
    rr_count INT,
    
    -- MÃ©tricas de tempo
    fc_mean FLOAT,
    sdnn FLOAT,
    rmssd FLOAT,
    pnn50 FLOAT,
    
    -- MÃ©tricas de frequÃªncia
    lf_power FLOAT,
    hf_power FLOAT,
    lf_hf_ratio FLOAT,
    
    -- Qualidade
    signal_quality FLOAT -- 0-100%
);

-- Dados MorfolÃ³gicos (check-up completo)
CREATE TABLE morphology_data (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID REFERENCES sessions(id) ON DELETE CASCADE,
    
    -- ParÃ¢metros de coleta
    sampling_rate_hz INT DEFAULT 757,
    duration_sec INT DEFAULT 40,
    
    -- Waveforms alta resoluÃ§Ã£o
    ir_waveform JSONB,
    red_waveform JSONB,
    
    -- MÃ©tricas de rigidez arterial
    ri_mean FLOAT, -- Reflection Index
    ri_std FLOAT,
    si_mean FLOAT, -- Stiffness Index
    si_std FLOAT,
    lvet_mean FLOAT, -- Left Ventricular Ejection Time
    
    -- APG (Acceleration Plethysmography)
    agi_mean FLOAT, -- Aging Index
    agi_std FLOAT,
    vascular_age_estimated INT,
    
    -- Qualidade
    signal_quality FLOAT,
    beats_analyzed INT
);
```

### ğŸ’¡ BenefÃ­cios desta Estrutura

1. **MigraÃ§Ã£o suave** - Tabela `hrv_sessions` atual pode ser mapeada para `sessions` + `hrv_data`
2. **Escalabilidade** - FÃ¡cil adicionar nova tabela para novos tipos de anÃ¡lise
3. **Queries eficientes** - Cada tabela tem apenas os campos relevantes
4. **Integridade** - FK com CASCADE garante consistÃªncia

---

## 3. EstratÃ©gia de Treinamento (DecimaÃ§Ã£o + Transfer Learning) {#treinamento}

### â“ DÃºvida Original

> "Podemos decimar de 200Hz para 125Hz para o treinamento com o dataset validado e fazer um transfer learning para os 200Hz depois?"

### ğŸ¤” AnÃ¡lise

Esta Ã© uma abordagem **hÃ­brida** que combina o melhor de dois mundos:

1. **Treino inicial em 125 Hz** â†’ Aproveita o MIMIC com ground truth ECG
2. **Transfer learning para 200 Hz** â†’ Adapta para a frequÃªncia de produÃ§Ã£o

### âœ… DecisÃ£o Final: Sim, Ã© a Melhor EstratÃ©gia

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE DE TREINAMENTO                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ETAPA 1: PRÃ‰-TREINAMENTO (MIMIC 125 Hz)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                   â”‚
â”‚  MIMIC PPG (125 Hz) â”€â”€â†’ Modelo Base â†â”€â”€ MIMIC ECG (Ground Truth) â”‚
â”‚                         (Performer)                               â”‚
â”‚                                                                   â”‚
â”‚  â€¢ Aprende: detecÃ§Ã£o de picos, padrÃµes de batimento              â”‚
â”‚  â€¢ Labels: picos R do ECG sincronizados                          â”‚
â”‚  â€¢ Loss: Binary CE (Ã© pico / nÃ£o Ã© pico)                         â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
ETAPA 2: ADAPTAÃ‡ÃƒO (Transfer Learning)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                   â”‚
â”‚  Seus dados PPG (200 Hz) â”€â”€â†’ Modelo Fine-tuned                   â”‚
â”‚                              (pesos do Modelo Base)               â”‚
â”‚                                                                   â”‚
â”‚  â€¢ TÃ©cnica: Upsample MIMIC para 200 Hz OU                        â”‚
â”‚             Pseudo-labels dos seus dados                          â”‚
â”‚  â€¢ Congela: primeiras camadas (features genÃ©ricas)               â”‚
â”‚  â€¢ Treina: Ãºltimas camadas (adaptaÃ§Ã£o de frequÃªncia)             â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
ETAPA 3: VALIDAÃ‡ÃƒO
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                   â”‚
â”‚  Compare:                                                         â”‚
â”‚  â€¢ Picos detectados pelo modelo vs algoritmo clÃ¡ssico            â”‚
â”‚  â€¢ RR intervals: MAE < 10ms Ã© aceitÃ¡vel                          â”‚
â”‚  â€¢ BPM error: < 2 BPM Ã© excelente                                â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’¡ Por que esta estratÃ©gia Ã© superior

| Aspecto | SÃ³ MIMIC (125 Hz) | SÃ³ Seus Dados (200 Hz) | HÃ­brido (escolhido) |
|---------|-------------------|------------------------|----------------------|
| Ground Truth | âœ… ECG real | âŒ Pseudo-labels | âœ… ECG + pseudo |
| Volume de dados | âœ… 53 pacientes | âš ï¸ Poucos inicialmente | âœ… Ambos |
| FrequÃªncia final | âŒ 125 Hz | âœ… 200 Hz | âœ… 200 Hz |
| GeneralizaÃ§Ã£o | âš ï¸ Pode nÃ£o transferir | âš ï¸ Overfitting | âœ… Robusto |

### ğŸ”§ ImplementaÃ§Ã£o Sugerida

```python
# Etapa 1: Treino no MIMIC
model = PPGPerformer(input_hz=125)
model.train(mimic_ppg, mimic_ecg_labels)
model.save("model_base_125hz.pt")

# Etapa 2: Upsample MIMIC para 200 Hz e continuar treino
mimic_200hz = upsample(mimic_ppg, from_hz=125, to_hz=200)
model_200 = PPGPerformer(input_hz=200)
model_200.load_weights("model_base_125hz.pt", adapt_layers=True)
model_200.finetune(mimic_200hz, mimic_ecg_labels)

# Etapa 3: Fine-tune com seus dados
your_data_200hz = load_your_data()
pseudo_labels = classical_peak_detector(your_data_200hz)
model_200.finetune(your_data_200hz, pseudo_labels, lr=1e-5)
```

---

## 4. PriorizaÃ§Ã£o do Desenvolvimento {#priorizacao}

### â“ DÃºvida Original

> "Vamos trabalhar com o desenvolvimento da 'mediÃ§Ã£o diÃ¡ria' primeiro assim jÃ¡ comeÃ§o a coletar os dados de diferentes pessoas"

### âœ… DecisÃ£o: Sim, "Meu Dia" (200 Hz) Primeiro

### ğŸ’¡ Justificativa

| CritÃ©rio | "Meu Dia" (200 Hz) | "Check-up Completo" (757 Hz) |
|----------|-------------------|------------------------------|
| **ValidaÃ§Ã£o** | FÃ¡cil (datasets HRV abundantes) | DifÃ­cil (poucos datasets morfolÃ³gicos) |
| **Demanda de mercado** | Alta (wellness, estresse) | Nicho (cardiologia) |
| **Complexidade tÃ©cnica** | Menor | Maior (APG, derivadas) |
| **Coleta de dados** | Qualquer pessoa | Precisa mais cuidado |
| **Tempo de mediÃ§Ã£o** | 5 min | 6+ min |

### ğŸ“‹ Roadmap Priorizado

```
ğŸ“ SPRINT 1: FundaÃ§Ã£o "Meu Dia" (2-3 semanas)
   â”œâ”€â”€ [ ] Firmware 200 Hz estÃ¡vel (baseado no v15)
   â”œâ”€â”€ [ ] Novo schema no Supabase (migrations)
   â”œâ”€â”€ [ ] App: tela "Meu Dia" com Start/Stop
   â”œâ”€â”€ [ ] Upload de dados via botÃ£o no app
   â””â”€â”€ [ ] Coleta de dados inicial (famÃ­lia, amigos)

ğŸ“ SPRINT 2: Pipeline de AnÃ¡lise (2-3 semanas)
   â”œâ”€â”€ [ ] Backend: extraÃ§Ã£o de RR intervals
   â”œâ”€â”€ [ ] Backend: cÃ¡lculo SDNN, RMSSD, pNN50
   â”œâ”€â”€ [ ] Backend: anÃ¡lise espectral (LF/HF)
   â”œâ”€â”€ [ ] App: visualizaÃ§Ã£o de resultados
   â””â”€â”€ [ ] ValidaÃ§Ã£o com dados coletados

ğŸ“ SPRINT 3: Modelo de ML (3-4 semanas)
   â”œâ”€â”€ [ ] Download e prÃ©-processamento do MIMIC
   â”œâ”€â”€ [ ] Treinamento do Performer em 125 Hz
   â”œâ”€â”€ [ ] Transfer learning para 200 Hz
   â”œâ”€â”€ [ ] ValidaÃ§Ã£o e fine-tuning
   â””â”€â”€ [ ] Deploy do modelo (edge ou cloud)

ğŸ“ SPRINT 4: "Check-up Completo" (4-5 semanas)
   â”œâ”€â”€ [ ] Firmware 757 Hz
   â”œâ”€â”€ [ ] App: tela "Check-up Completo"
   â”œâ”€â”€ [ ] Pipeline de morfologia (RI, SI, APG)
   â””â”€â”€ [ ] IntegraÃ§Ã£o com sessÃ£o diÃ¡ria
```

### ğŸ¯ Meta Imediata

**Ao final do Sprint 1:**
- ESP32 coletando dados 200 Hz de forma confiÃ¡vel
- App com botÃ£o "Meu Dia" funcionando
- Dados sendo salvos no Supabase com novo schema
- Pronto para coletar dados em campo

---

## ğŸ“ Registro de DecisÃµes (Decision Log)

| Data | DecisÃ£o | Justificativa | Impacto |
|------|---------|---------------|---------|
| 2026-01-18 | Treinar em 200 Hz (vs 125 Hz) | Evita overhead de decimaÃ§Ã£o em real-time | Pipeline de produÃ§Ã£o simplificado |
| 2026-01-18 | Schema normalizado (3 tabelas) | Flexibilidade e escalabilidade | MigraÃ§Ã£o do schema atual necessÃ¡ria |
| 2026-01-18 | HÃ­brido: MIMIC + Transfer Learning | Combina ground truth com adaptaÃ§Ã£o | 2 etapas de treinamento |
| 2026-01-18 | Priorizar "Meu Dia" | ValidaÃ§Ã£o mais fÃ¡cil, coleta de dados | Check-up Completo adiado para Sprint 4 |
| 2026-01-18 | Nomes UX: "Meu Dia" / "Check-up Completo" | ComunicaÃ§Ã£o clara de benefÃ­cio | MudanÃ§a de nomenclatura no app |

---

## ğŸ† Valor para o PortfÃ³lio

Este documento demonstra:

1. **Pensamento sistÃªmico** - Considerar impacto de decisÃµes tÃ©cnicas em produÃ§Ã£o
2. **Trade-off analysis** - Avaliar mÃºltiplas opÃ§Ãµes antes de decidir
3. **Viabilidade econÃ´mica** - Escolher soluÃ§Ãµes que minimizam overhead operacional
4. **UX-first thinking** - Nomear features pelo benefÃ­cio, nÃ£o pela tÃ©cnica
5. **Arquitetura escalÃ¡vel** - Design de banco de dados que crescerÃ¡ com o projeto
6. **Pragmatismo** - Priorizar o que gera valor mais rÃ¡pido (coleta de dados)

---

*Documento criado em 2026-01-18 | Douglas Freitas*
