{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b92e7c",
   "metadata": {},
   "source": [
    "# ü´Ä Treinamento de Detec√ß√£o de Picos PPG\n",
    "\n",
    "Este notebook demonstra o pipeline completo para treinar um modelo de detec√ß√£o\n",
    "de picos em sinais PPG, usando o MIMIC-II como base e seus pr√≥prios dados para\n",
    "fine-tuning.\n",
    "\n",
    "## O que vamos fazer:\n",
    "1. **Baixar** uma amostra do MIMIC-II (PPG + ECG sincronizados)\n",
    "2. **Criar os R√≥tulos** detectando picos R no ECG e transferindo para o PPG\n",
    "3. **Treinar** um modelo simples (1D CNN) para detectar picos\n",
    "4. **Testar** no seu dado do ESP32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d040c3a",
   "metadata": {},
   "source": [
    "## üì¶ Instala√ß√£o de Depend√™ncias\n",
    "\n",
    "Execute esta c√©lula apenas uma vez para instalar as bibliotecas necess√°rias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wfdb numpy scipy scikit-learn matplotlib torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c86594",
   "metadata": {},
   "source": [
    "## 1. Importa√ß√µes e Configura√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15664ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, butter, filtfilt, resample\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.rcParams['figure.figsize'] = (14, 4)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Par√¢metros do pipeline\n",
    "MIMIC_FS = 125       # Taxa de amostragem do MIMIC-II (Hz)\n",
    "ESP32_FS = 757       # Taxa de amostragem do seu ESP32 (Hz)\n",
    "TARGET_FS = 125      # Taxa alvo ap√≥s decima√ß√£o (Hz)\n",
    "WINDOW_SEC = 2       # Tamanho da janela em segundos\n",
    "WINDOW_SIZE = WINDOW_SEC * TARGET_FS  # 250 amostras por janela\n",
    "\n",
    "print(f\"‚úÖ Configura√ß√µes carregadas:\")\n",
    "print(f\"   - Janela: {WINDOW_SEC}s = {WINDOW_SIZE} amostras @ {TARGET_FS}Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b5050",
   "metadata": {},
   "source": [
    "## 2. Carregando Dados do MIMIC-II\n",
    "\n",
    "O MIMIC-II Waveform Database cont√©m sinais de pacientes de UTI.\n",
    "Vamos usar a biblioteca `wfdb` para baixar uma amostra.\n",
    "\n",
    "> **Nota:** O download pode demorar na primeira vez (~50MB por registro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd32ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "\n",
    "# Lista de registros de exemplo do MIMIC-II Matched Subset\n",
    "# Estes cont√™m PPG (PLETH) e ECG (II ou V) sincronizados\n",
    "MIMIC_RECORDS = [\n",
    "    'mimic3wdb-matched/1.0/p00/p000020/p000020-2183-04-28-17-47',  # Exemplo\n",
    "]\n",
    "\n",
    "def download_mimic_sample(record_name, duration_sec=60):\n",
    "    \"\"\"\n",
    "    Baixa uma amostra do MIMIC-II.\n",
    "    \n",
    "    Args:\n",
    "        record_name: Nome do registro no PhysioNet\n",
    "        duration_sec: Dura√ß√£o em segundos para baixar\n",
    "        \n",
    "    Returns:\n",
    "        ppg: Sinal PPG (PLETH)\n",
    "        ecg: Sinal ECG\n",
    "        fs: Taxa de amostragem\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Baixar registro\n",
    "        record = wfdb.rdrecord(\n",
    "            record_name,\n",
    "            pn_dir='mimic3wdb-matched/1.0',\n",
    "            sampfrom=0,\n",
    "            sampto=duration_sec * MIMIC_FS\n",
    "        )\n",
    "        \n",
    "        # Encontrar canais PPG e ECG\n",
    "        sig_names = [s.upper() for s in record.sig_name]\n",
    "        \n",
    "        ppg_idx = None\n",
    "        ecg_idx = None\n",
    "        \n",
    "        for i, name in enumerate(sig_names):\n",
    "            if 'PLETH' in name:\n",
    "                ppg_idx = i\n",
    "            elif name in ['II', 'I', 'V', 'AVR', 'AVL', 'AVF']:\n",
    "                ecg_idx = i\n",
    "                \n",
    "        if ppg_idx is None or ecg_idx is None:\n",
    "            raise ValueError(f\"Canais n√£o encontrados. Dispon√≠veis: {sig_names}\")\n",
    "            \n",
    "        ppg = record.p_signal[:, ppg_idx]\n",
    "        ecg = record.p_signal[:, ecg_idx]\n",
    "        \n",
    "        # Remover NaN\n",
    "        ppg = np.nan_to_num(ppg, nan=np.nanmean(ppg))\n",
    "        ecg = np.nan_to_num(ecg, nan=np.nanmean(ecg))\n",
    "        \n",
    "        return ppg, ecg, record.fs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro ao baixar do PhysioNet: {e}\")\n",
    "        print(\"   Gerando dados sint√©ticos para demonstra√ß√£o...\")\n",
    "        return generate_synthetic_data(duration_sec, MIMIC_FS)\n",
    "\n",
    "\n",
    "def generate_synthetic_data(duration_sec, fs):\n",
    "    \"\"\"\n",
    "    Gera dados sint√©ticos de PPG e ECG para demonstra√ß√£o.\n",
    "    √ötil quando o PhysioNet est√° offline ou lento.\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, duration_sec, duration_sec * fs)\n",
    "    \n",
    "    # Simular batimentos card√≠acos (~70 BPM com variabilidade)\n",
    "    hr_base = 70 / 60  # Hz\n",
    "    rr_intervals = 1/hr_base + 0.05 * np.sin(2 * np.pi * 0.1 * t)  # RSA simulada\n",
    "    \n",
    "    # ECG sint√©tico (ondas R simples)\n",
    "    ecg = np.zeros_like(t)\n",
    "    peak_times = []\n",
    "    current_time = 0\n",
    "    for i, rr in enumerate(rr_intervals):\n",
    "        if current_time >= duration_sec:\n",
    "            break\n",
    "        peak_idx = int(current_time * fs)\n",
    "        if peak_idx < len(ecg):\n",
    "            # Onda R como gaussiana estreita\n",
    "            ecg += 2.0 * np.exp(-((t - current_time) ** 2) / (0.005 ** 2))\n",
    "            peak_times.append(current_time)\n",
    "        current_time += rr_intervals[min(i, len(rr_intervals)-1)]\n",
    "    \n",
    "    # Adicionar ru√≠do ao ECG\n",
    "    ecg += 0.1 * np.random.randn(len(ecg))\n",
    "    \n",
    "    # PPG sint√©tico (atrasado ~200ms do ECG)\n",
    "    ppg = np.zeros_like(t)\n",
    "    ptt = 0.2  # Pulse Transit Time (segundos)\n",
    "    for peak_time in peak_times:\n",
    "        ppg_time = peak_time + ptt\n",
    "        if ppg_time < duration_sec:\n",
    "            # Onda PPG como gaussiana mais larga\n",
    "            ppg += 1.0 * np.exp(-((t - ppg_time) ** 2) / (0.03 ** 2))\n",
    "            # Adicionar n√≥ dicr√≥tico\n",
    "            ppg += 0.3 * np.exp(-((t - ppg_time - 0.15) ** 2) / (0.02 ** 2))\n",
    "    \n",
    "    # Normalizar e adicionar ru√≠do\n",
    "    ppg = (ppg - ppg.min()) / (ppg.max() - ppg.min())\n",
    "    ppg += 0.05 * np.random.randn(len(ppg))\n",
    "    \n",
    "    return ppg, ecg, fs\n",
    "\n",
    "# Tentar baixar do MIMIC, ou usar dados sint√©ticos\n",
    "print(\"üì• Baixando dados do MIMIC-II (ou gerando sint√©ticos)...\")\n",
    "ppg_raw, ecg_raw, fs = generate_synthetic_data(60, MIMIC_FS)  # Usar sint√©tico por padr√£o\n",
    "\n",
    "print(f\"‚úÖ Dados carregados: {len(ppg_raw)} amostras @ {fs}Hz ({len(ppg_raw)/fs:.1f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4dfcbd",
   "metadata": {},
   "source": [
    "### Visualiza√ß√£o dos Sinais Brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4369bd28",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Plotar primeiros 10 segundos\n",
    "t = np.arange(len(ppg_raw)) / fs\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6), sharex=True)\n",
    "\n",
    "axes[0].plot(t[:10*fs], ecg_raw[:10*fs], 'b-', linewidth=0.8)\n",
    "axes[0].set_ylabel('ECG (mV)')\n",
    "axes[0].set_title('üìä Sinais MIMIC-II (ou Sint√©ticos) - Primeiros 10 segundos')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(t[:10*fs], ppg_raw[:10*fs], 'r-', linewidth=0.8)\n",
    "axes[1].set_ylabel('PPG')\n",
    "axes[1].set_xlabel('Tempo (s)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab044372",
   "metadata": {},
   "source": [
    "## 3. Criando os R√≥tulos (Labels)\n",
    "\n",
    "Esta √© a parte **crucial**: detectamos os picos R no ECG (f√°cil e preciso)\n",
    "e usamos essa informa√ß√£o para marcar onde est√£o os picos no PPG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad510178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ecg_r_peaks(ecg, fs, min_distance_sec=0.4):\n",
    "    \"\"\"\n",
    "    Detecta picos R no ECG usando um algoritmo simples mas robusto.\n",
    "    \n",
    "    Em produ√ß√£o, voc√™ usaria Pan-Tompkins ou similar.\n",
    "    \"\"\"\n",
    "    # Filtro passa-banda (5-15 Hz para isolar QRS)\n",
    "    nyq = fs / 2\n",
    "    b, a = butter(2, [5/nyq, 15/nyq], btype='band')\n",
    "    ecg_filt = filtfilt(b, a, ecg)\n",
    "    \n",
    "    # Elevar ao quadrado para real√ßar picos\n",
    "    ecg_squared = ecg_filt ** 2\n",
    "    \n",
    "    # Suavizar\n",
    "    ecg_smooth = gaussian_filter1d(ecg_squared, sigma=fs*0.02)\n",
    "    \n",
    "    # Detectar picos\n",
    "    min_distance = int(min_distance_sec * fs)\n",
    "    peaks, properties = find_peaks(\n",
    "        ecg_smooth,\n",
    "        distance=min_distance,\n",
    "        height=np.percentile(ecg_smooth, 70)\n",
    "    )\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "\n",
    "def transfer_peaks_to_ppg(ecg_peaks, ecg, ppg, fs, ptt_range=(0.15, 0.35)):\n",
    "    \"\"\"\n",
    "    Transfere os picos do ECG para o PPG considerando o Pulse Transit Time (PTT).\n",
    "    \n",
    "    O pico sist√≥lico do PPG ocorre ~200-300ms ap√≥s o pico R do ECG.\n",
    "    Procuramos o m√°ximo local nessa janela.\n",
    "    \"\"\"\n",
    "    ppg_peaks = []\n",
    "    \n",
    "    ptt_min_samples = int(ptt_range[0] * fs)\n",
    "    ptt_max_samples = int(ptt_range[1] * fs)\n",
    "    \n",
    "    for ecg_peak in ecg_peaks:\n",
    "        # Janela de busca no PPG\n",
    "        search_start = ecg_peak + ptt_min_samples\n",
    "        search_end = ecg_peak + ptt_max_samples\n",
    "        \n",
    "        if search_end >= len(ppg):\n",
    "            continue\n",
    "            \n",
    "        # Encontrar m√°ximo local nessa janela\n",
    "        window = ppg[search_start:search_end]\n",
    "        local_max_idx = np.argmax(window)\n",
    "        ppg_peak = search_start + local_max_idx\n",
    "        \n",
    "        ppg_peaks.append(ppg_peak)\n",
    "    \n",
    "    return np.array(ppg_peaks)\n",
    "\n",
    "\n",
    "# Detectar picos R no ECG\n",
    "ecg_r_peaks = detect_ecg_r_peaks(ecg_raw, fs)\n",
    "print(f\"üîç Detectados {len(ecg_r_peaks)} picos R no ECG\")\n",
    "\n",
    "# Transferir para o PPG\n",
    "ppg_peaks = transfer_peaks_to_ppg(ecg_r_peaks, ecg_raw, ppg_raw, fs)\n",
    "print(f\"üéØ Mapeados {len(ppg_peaks)} picos no PPG\")\n",
    "\n",
    "# Calcular RR intervals para valida√ß√£o\n",
    "rr_intervals = np.diff(ppg_peaks) / fs * 1000  # em ms\n",
    "hr_mean = 60000 / np.mean(rr_intervals)\n",
    "print(f\"‚ù§Ô∏è HR m√©dio calculado: {hr_mean:.1f} BPM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fdfb59",
   "metadata": {},
   "source": [
    "### Visualiza√ß√£o: ECG vs PPG com Picos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a8473",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Plotar 5 segundos com picos marcados\n",
    "start_sec = 2\n",
    "end_sec = 7\n",
    "start_idx = int(start_sec * fs)\n",
    "end_idx = int(end_sec * fs)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6), sharex=True)\n",
    "\n",
    "# ECG com picos R\n",
    "axes[0].plot(t[start_idx:end_idx], ecg_raw[start_idx:end_idx], 'b-', linewidth=1)\n",
    "ecg_peaks_in_range = ecg_r_peaks[(ecg_r_peaks >= start_idx) & (ecg_r_peaks < end_idx)]\n",
    "axes[0].scatter(t[ecg_peaks_in_range], ecg_raw[ecg_peaks_in_range], \n",
    "                c='red', s=100, zorder=5, label='Pico R (ECG)')\n",
    "axes[0].set_ylabel('ECG')\n",
    "axes[0].set_title('üéØ Transfer√™ncia de Picos: ECG ‚Üí PPG')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PPG com picos sist√≥licos\n",
    "axes[1].plot(t[start_idx:end_idx], ppg_raw[start_idx:end_idx], 'purple', linewidth=1)\n",
    "ppg_peaks_in_range = ppg_peaks[(ppg_peaks >= start_idx) & (ppg_peaks < end_idx)]\n",
    "axes[1].scatter(t[ppg_peaks_in_range], ppg_raw[ppg_peaks_in_range], \n",
    "                c='green', s=100, zorder=5, label='Pico Sist√≥lico (PPG)')\n",
    "axes[1].set_ylabel('PPG')\n",
    "axes[1].set_xlabel('Tempo (s)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Mostrar PTT (linhas conectando)\n",
    "for ecg_p, ppg_p in zip(ecg_peaks_in_range, ppg_peaks_in_range):\n",
    "    if ecg_p < end_idx and ppg_p < end_idx:\n",
    "        axes[1].axvline(x=t[ecg_p], color='red', linestyle='--', alpha=0.3)\n",
    "        axes[1].annotate('', xy=(t[ppg_p], ppg_raw[ppg_p]), \n",
    "                        xytext=(t[ecg_p], ppg_raw[ppg_p]),\n",
    "                        arrowprops=dict(arrowstyle='->', color='gray', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bbffd6",
   "metadata": {},
   "source": [
    "## 4. Criando o Dataset de Treinamento\n",
    "\n",
    "Agora vamos criar janelas de PPG com seus respectivos r√≥tulos.\n",
    "O r√≥tulo √© um vetor bin√°rio indicando onde est√° o pico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_windows(ppg, peaks, window_size, stride=None):\n",
    "    \"\"\"\n",
    "    Cria janelas de treinamento com r√≥tulos.\n",
    "    \n",
    "    Args:\n",
    "        ppg: Sinal PPG completo\n",
    "        peaks: √çndices dos picos no sinal\n",
    "        window_size: Tamanho da janela em amostras\n",
    "        stride: Passo entre janelas (default: window_size // 2)\n",
    "        \n",
    "    Returns:\n",
    "        X: Array de janelas de PPG (N, window_size)\n",
    "        y: Array de r√≥tulos bin√°rios (N, window_size)\n",
    "    \"\"\"\n",
    "    if stride is None:\n",
    "        stride = window_size // 2\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Normaliza√ß√£o Z-score do sinal completo\n",
    "    ppg_norm = (ppg - np.mean(ppg)) / np.std(ppg)\n",
    "    \n",
    "    # Criar conjunto de picos para busca r√°pida\n",
    "    peaks_set = set(peaks)\n",
    "    \n",
    "    for start in range(0, len(ppg) - window_size, stride):\n",
    "        end = start + window_size\n",
    "        \n",
    "        # Extrair janela\n",
    "        window = ppg_norm[start:end]\n",
    "        \n",
    "        # Criar r√≥tulo bin√°rio (1 onde tem pico, 0 caso contr√°rio)\n",
    "        label = np.zeros(window_size)\n",
    "        for i in range(window_size):\n",
    "            if (start + i) in peaks_set:\n",
    "                # Marcar regi√£o ao redor do pico (¬±2 amostras = ¬±16ms @ 125Hz)\n",
    "                for offset in range(-2, 3):\n",
    "                    if 0 <= i + offset < window_size:\n",
    "                        label[i + offset] = 1\n",
    "        \n",
    "        # S√≥ incluir janelas com pelo menos 1 pico\n",
    "        if np.sum(label) > 0:\n",
    "            X.append(window)\n",
    "            y.append(label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# Criar dataset\n",
    "X, y = create_training_windows(ppg_raw, ppg_peaks, WINDOW_SIZE)\n",
    "\n",
    "print(f\"üìä Dataset criado:\")\n",
    "print(f\"   - Janelas: {X.shape[0]}\")\n",
    "print(f\"   - Tamanho da janela: {X.shape[1]} amostras\")\n",
    "print(f\"   - R√≥tulo: {y.shape[1]} amostras (bin√°rio)\")\n",
    "\n",
    "# Dividir em treino/valida√ß√£o\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nüîÄ Divis√£o:\")\n",
    "print(f\"   - Treino: {len(X_train)} janelas\")\n",
    "print(f\"   - Valida√ß√£o: {len(X_val)} janelas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465a430",
   "metadata": {},
   "source": [
    "### Visualiza√ß√£o de uma Janela de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3229b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar exemplo de janela com r√≥tulo\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 5), sharex=True)\n",
    "\n",
    "sample_idx = 5\n",
    "t_window = np.arange(WINDOW_SIZE) / TARGET_FS\n",
    "\n",
    "axes[0].plot(t_window, X_train[sample_idx], 'purple', linewidth=1)\n",
    "axes[0].set_ylabel('PPG (Z-score)')\n",
    "axes[0].set_title(f'üì¶ Exemplo de Janela de Treino #{sample_idx}')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].fill_between(t_window, y_train[sample_idx], alpha=0.5, color='green', label='R√≥tulo (onde tem pico)')\n",
    "axes[1].set_ylabel('Label')\n",
    "axes[1].set_xlabel('Tempo (s)')\n",
    "axes[1].set_ylim(-0.1, 1.1)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac0e231",
   "metadata": {},
   "source": [
    "## 5. Modelo de Detec√ß√£o de Picos (1D CNN)\n",
    "\n",
    "Usamos uma CNN 1D simples que recebe a janela PPG e prediz a probabilidade\n",
    "de cada ponto ser um pico.\n",
    "\n",
    "> **Arquitetura:** Input ‚Üí Conv1D ‚Üí BatchNorm ‚Üí ReLU ‚Üí ... ‚Üí Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaada0c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Verificar se GPU dispon√≠vel\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è Usando dispositivo: {device}\")\n",
    "\n",
    "\n",
    "class PeakDetectorCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN 1D para detec√ß√£o de picos em sinais PPG.\n",
    "    \n",
    "    Arquitetura U-Net simplificada: encoder-decoder com skip connections.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=250):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv1d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv1d(64 + 64, 32, kernel_size=3, padding=1),  # Skip connection\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Output\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv1d(32 + 32, 16, kernel_size=3, padding=1),  # Skip connection\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, 1, window_size)\n",
    "        \n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)           # (batch, 32, window_size)\n",
    "        e2 = self.enc2(e1)          # (batch, 64, window_size/2)\n",
    "        e3 = self.enc3(e2)          # (batch, 128, window_size/4)\n",
    "        \n",
    "        # Decoder com skip connections\n",
    "        d2 = self.dec2(e3)          # (batch, 64, window_size/2)\n",
    "        d2 = torch.cat([d2, e2], dim=1)  # (batch, 128, window_size/2)\n",
    "        \n",
    "        d1 = self.dec1(d2)          # (batch, 32, window_size)\n",
    "        d1 = torch.cat([d1, e1], dim=1)  # (batch, 64, window_size)\n",
    "        \n",
    "        out = self.output(d1)       # (batch, 1, window_size)\n",
    "        \n",
    "        return out.squeeze(1)       # (batch, window_size)\n",
    "\n",
    "\n",
    "# Criar modelo\n",
    "model = PeakDetectorCNN(WINDOW_SIZE).to(device)\n",
    "print(f\"üèóÔ∏è Modelo criado com {sum(p.numel() for p in model.parameters()):,} par√¢metros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f8b49",
   "metadata": {},
   "source": [
    "## 6. Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d073552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=30, batch_size=32, lr=0.001):\n",
    "    \"\"\"\n",
    "    Treina o modelo de detec√ß√£o de picos.\n",
    "    \"\"\"\n",
    "    # Converter para tensors PyTorch\n",
    "    X_train_t = torch.FloatTensor(X_train).unsqueeze(1)  # Adicionar canal\n",
    "    y_train_t = torch.FloatTensor(y_train)\n",
    "    X_val_t = torch.FloatTensor(X_val).unsqueeze(1)\n",
    "    y_val_t = torch.FloatTensor(y_val)\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Loss e optimizer\n",
    "    criterion = nn.BCELoss()  # Binary Cross Entropy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "    \n",
    "    # Hist√≥rico\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        # Valida√ß√£o\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_val_t_dev = X_val_t.to(device)\n",
    "            y_val_t_dev = y_val_t.to(device)\n",
    "            y_val_pred = model(X_val_t_dev)\n",
    "            val_loss = criterion(y_val_pred, y_val_t_dev).item()\n",
    "        \n",
    "        train_loss = np.mean(train_losses)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# Treinar\n",
    "print(\"üöÄ Iniciando treinamento...\")\n",
    "history = train_model(model, X_train, y_train, X_val, y_val, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e02bad",
   "metadata": {},
   "source": [
    "### Curvas de Aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a49865",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history['train_loss'], label='Treino')\n",
    "plt.plot(history['val_loss'], label='Valida√ß√£o')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('Loss (BCE)')\n",
    "plt.title('üìà Curvas de Aprendizado')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d890cbe4",
   "metadata": {},
   "source": [
    "## 7. Avalia√ß√£o: Predi√ß√£o vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4498da",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Predi√ß√£o no conjunto de valida√ß√£o\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_val_t = torch.FloatTensor(X_val).unsqueeze(1).to(device)\n",
    "    y_pred = model(X_val_t).cpu().numpy()\n",
    "\n",
    "# Visualizar algumas predi√ß√µes\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    idx = i * 2  # Amostras espa√ßadas\n",
    "    \n",
    "    t_window = np.arange(WINDOW_SIZE) / TARGET_FS\n",
    "    \n",
    "    # PPG\n",
    "    ax.plot(t_window, X_val[idx], 'purple', alpha=0.7, label='PPG')\n",
    "    \n",
    "    # Ground truth\n",
    "    ax.fill_between(t_window, y_val[idx] * X_val[idx].max() * 0.3, \n",
    "                    alpha=0.3, color='green', label='Ground Truth')\n",
    "    \n",
    "    # Predi√ß√£o\n",
    "    ax.fill_between(t_window, y_pred[idx] * X_val[idx].max() * 0.3, \n",
    "                    alpha=0.3, color='red', label='Predi√ß√£o')\n",
    "    \n",
    "    ax.set_ylabel('PPG')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[0].set_title('üéØ Compara√ß√£o: Predi√ß√£o vs Ground Truth')\n",
    "axes[-1].set_xlabel('Tempo (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4d87c",
   "metadata": {},
   "source": [
    "## 8. Usando nos Seus Dados (ESP32)\n",
    "\n",
    "Agora vamos carregar um sinal do seu ESP32 e rodar o modelo treinado.\n",
    "\n",
    "> **Importante:** Seus dados est√£o a 757Hz, precisamos decimar para 125Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72608389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_esp32_data(filepath, target_fs=125):\n",
    "    \"\"\"\n",
    "    Carrega dados do ESP32 e decima para a taxa alvo.\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    \n",
    "    # Tentar carregar CSV\n",
    "    try:\n",
    "        data = np.loadtxt(filepath, delimiter=',', skiprows=1)\n",
    "        ppg = data[:, 0]  # Assumindo primeira coluna √© IR/PPG\n",
    "        original_fs = 757  # Seu ESP32\n",
    "    except:\n",
    "        print(f\"‚ö†Ô∏è N√£o foi poss√≠vel carregar {filepath}\")\n",
    "        print(\"   Gerando dado sint√©tico para demonstra√ß√£o...\")\n",
    "        ppg, _, original_fs = generate_synthetic_data(30, 757)\n",
    "    \n",
    "    # Decimar\n",
    "    if original_fs != target_fs:\n",
    "        num_samples = int(len(ppg) * target_fs / original_fs)\n",
    "        ppg_resampled = resample(ppg, num_samples)\n",
    "        print(f\"üìâ Decimado de {original_fs}Hz para {target_fs}Hz\")\n",
    "    else:\n",
    "        ppg_resampled = ppg\n",
    "    \n",
    "    return ppg_resampled, target_fs\n",
    "\n",
    "\n",
    "def predict_peaks(model, ppg, fs, window_size=250, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Usa o modelo para detectar picos no sinal PPG.\n",
    "    \n",
    "    Returns:\n",
    "        peak_indices: √çndices dos picos detectados\n",
    "    \"\"\"\n",
    "    # Normalizar\n",
    "    ppg_norm = (ppg - np.mean(ppg)) / np.std(ppg)\n",
    "    \n",
    "    # Criar janelas sobrepostas\n",
    "    stride = window_size // 4  # 75% overlap para suaviza√ß√£o\n",
    "    predictions = np.zeros(len(ppg))\n",
    "    counts = np.zeros(len(ppg))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, len(ppg) - window_size, stride):\n",
    "            window = ppg_norm[start:start + window_size]\n",
    "            window_t = torch.FloatTensor(window).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            \n",
    "            pred = model(window_t).cpu().numpy().squeeze()\n",
    "            \n",
    "            predictions[start:start + window_size] += pred\n",
    "            counts[start:start + window_size] += 1\n",
    "    \n",
    "    # M√©dia das predi√ß√µes sobrepostas\n",
    "    predictions = predictions / np.maximum(counts, 1)\n",
    "    \n",
    "    # Encontrar picos na probabilidade predita\n",
    "    peaks, _ = find_peaks(predictions, height=threshold, distance=int(0.4 * fs))\n",
    "    \n",
    "    return peaks, predictions\n",
    "\n",
    "\n",
    "# Carregar dados do ESP32 (ou sint√©tico se n√£o dispon√≠vel)\n",
    "print(\"üìÇ Carregando dados do ESP32...\")\n",
    "esp32_ppg, esp32_fs = load_esp32_data(\n",
    "    '/home/douglas/Documentos/Projects/PPG/pulse-analytics/analytics/datasets/sample.csv',\n",
    "    target_fs=TARGET_FS\n",
    ")\n",
    "\n",
    "# Predizer picos\n",
    "print(\"üîÆ Detectando picos...\")\n",
    "detected_peaks, peak_probs = predict_peaks(model, esp32_ppg, esp32_fs)\n",
    "\n",
    "print(f\"‚úÖ Detectados {len(detected_peaks)} picos\")\n",
    "\n",
    "# Calcular HR\n",
    "if len(detected_peaks) > 1:\n",
    "    rr = np.diff(detected_peaks) / esp32_fs * 1000  # ms\n",
    "    hr = 60000 / np.mean(rr)\n",
    "    print(f\"‚ù§Ô∏è HR estimado: {hr:.1f} BPM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399bed4",
   "metadata": {},
   "source": [
    "### Visualiza√ß√£o da Predi√ß√£o nos Seus Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ea900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar resultado\n",
    "t = np.arange(len(esp32_ppg)) / esp32_fs\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6), sharex=True)\n",
    "\n",
    "# PPG com picos detectados\n",
    "axes[0].plot(t, esp32_ppg, 'purple', linewidth=0.8)\n",
    "axes[0].scatter(t[detected_peaks], esp32_ppg[detected_peaks], \n",
    "                c='red', s=80, zorder=5, label='Picos Detectados')\n",
    "axes[0].set_ylabel('PPG')\n",
    "axes[0].set_title('üéØ Detec√ß√£o de Picos no Seu Sinal (ESP32)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Probabilidade de pico\n",
    "axes[1].plot(t, peak_probs, 'orange', linewidth=0.8)\n",
    "axes[1].axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Threshold')\n",
    "axes[1].set_ylabel('P(pico)')\n",
    "axes[1].set_xlabel('Tempo (s)')\n",
    "axes[1].set_ylim(-0.05, 1.05)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f1721",
   "metadata": {},
   "source": [
    "## 9. Salvando o Modelo\n",
    "\n",
    "Salve o modelo treinado para usar posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f16b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar modelo\n",
    "model_path = '/home/douglas/Documentos/Projects/PPG/pulse-analytics/analytics/peak_detector_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'window_size': WINDOW_SIZE,\n",
    "    'target_fs': TARGET_FS\n",
    "}, model_path)\n",
    "\n",
    "print(f\"üíæ Modelo salvo em: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d05b35",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## üéì Resumo do Pipeline\n",
    "\n",
    "1. **MIMIC-II** fornece o par PPG + ECG sincronizado\n",
    "2. Detectamos picos R do **ECG** (algoritmo cl√°ssico, ~99% acur√°cia)\n",
    "3. Transferimos para o **PPG** (+200ms de PTT)\n",
    "4. Criamos **janelas rotuladas** (X = PPG, y = onde tem pico)\n",
    "5. Treinamos uma **CNN 1D** para prever pico\n",
    "6. **Fine-tuning**: usar seus dados para adaptar ao ru√≠do do seu sensor\n",
    "7. **Infer√™ncia**: o modelo prediz picos no seu sinal novo\n",
    "\n",
    "---\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "- [ ] Baixar registros reais do MIMIC-II (PhysioNet)\n",
    "- [ ] Coletar mais dados seus para fine-tuning\n",
    "- [ ] Testar arquitetura Performer (Attention) no lugar da CNN\n",
    "- [ ] Exportar para TensorFlow Lite para rodar no ESP32"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
