{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "effa2183",
   "metadata": {},
   "source": [
    "# ü´Ä Detec√ß√£o de Picos PPG com Performer (Transformer)\n",
    "\n",
    "Este notebook usa os dados **locais do MIMIC-II** (BIDMC) e treina um modelo\n",
    "**Performer** (Transformer com aten√ß√£o linear O(n)) para detectar picos sist√≥licos.\n",
    "\n",
    "## Pipeline:\n",
    "1. Carregar os 53 registros locais (BIDMC)\n",
    "2. Detectar picos R no ECG (Lead II) ‚Üí criar labels para PPG\n",
    "3. Treinar Performer para prever posi√ß√£o do pico\n",
    "4. Valida√ß√£o Leave-One-Subject-Out (LOSO)\n",
    "5. Testar nos seus dados ESP32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf685a3",
   "metadata": {},
   "source": [
    "## üì¶ Instala√ß√£o de Depend√™ncias\n",
    "\n",
    "Execute apenas uma vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy scikit-learn matplotlib torch einops performer-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956750fd",
   "metadata": {},
   "source": [
    "## 1. Importa√ß√µes e Configura√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a57f0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, butter, filtfilt, resample\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes\n",
    "plt.rcParams['figure.figsize'] = (14, 4)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Par√¢metros\n",
    "FS = 125                    # Taxa de amostragem BIDMC (Hz)\n",
    "WINDOW_SEC = 4              # Janela de 4 segundos\n",
    "WINDOW_SIZE = WINDOW_SEC * FS  # 500 amostras\n",
    "STRIDE = WINDOW_SIZE // 2   # 50% overlap\n",
    "\n",
    "# Caminhos\n",
    "MIMIC_DIR = '/home/douglas/Documentos/Projects/PPG/pulse-analytics/analytics/datasets/ MIMIC II'\n",
    "ESP32_DIR = '/home/douglas/Documentos/Projects/PPG/pulse-analytics/analytics/datasets'\n",
    "\n",
    "print(f\"‚úÖ Configura√ß√µes:\")\n",
    "print(f\"   - Janela: {WINDOW_SEC}s = {WINDOW_SIZE} samples @ {FS}Hz\")\n",
    "print(f\"   - Dataset: {MIMIC_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa9448e",
   "metadata": {},
   "source": [
    "## 2. Carregando Dados Locais BIDMC (MIMIC-II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bidmc_record(filepath):\n",
    "    \"\"\"\n",
    "    Carrega um registro BIDMC do CSV local.\n",
    "    \n",
    "    Returns:\n",
    "        ppg: Sinal PPG (PLETH)\n",
    "        ecg: Sinal ECG (Lead II)\n",
    "        fs: Taxa de amostragem (125Hz)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Extrair sinais\n",
    "    ppg = df['PLETH'].values\n",
    "    ecg = df['II'].values\n",
    "    \n",
    "    # Remover NaN\n",
    "    ppg = np.nan_to_num(ppg, nan=np.nanmean(ppg))\n",
    "    ecg = np.nan_to_num(ecg, nan=np.nanmean(ecg))\n",
    "    \n",
    "    return ppg, ecg, FS\n",
    "\n",
    "\n",
    "def load_all_subjects(mimic_dir):\n",
    "    \"\"\"\n",
    "    Carrega todos os 53 sujeitos do BIDMC.\n",
    "    \n",
    "    Returns:\n",
    "        subjects: Lista de dicts com 'id', 'ppg', 'ecg'\n",
    "    \"\"\"\n",
    "    pattern = os.path.join(mimic_dir, 'bidmc_*_Signals.csv')\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    \n",
    "    subjects = []\n",
    "    for filepath in files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        subject_id = filename.split('_')[1]  # Ex: \"01\", \"02\", etc.\n",
    "        \n",
    "        try:\n",
    "            ppg, ecg, fs = load_bidmc_record(filepath)\n",
    "            subjects.append({\n",
    "                'id': subject_id,\n",
    "                'ppg': ppg,\n",
    "                'ecg': ecg,\n",
    "                'fs': fs,\n",
    "                'filepath': filepath\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erro ao carregar {filename}: {e}\")\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "\n",
    "# Carregar todos os sujeitos\n",
    "print(\"üìÇ Carregando dataset BIDMC...\")\n",
    "subjects = load_all_subjects(MIMIC_DIR)\n",
    "print(f\"‚úÖ Carregados {len(subjects)} sujeitos\")\n",
    "\n",
    "# Estat√≠sticas\n",
    "total_minutes = sum(len(s['ppg']) / s['fs'] / 60 for s in subjects)\n",
    "print(f\"üìä Total de dados: {total_minutes:.1f} minutos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab54830c",
   "metadata": {},
   "source": [
    "### Visualiza√ß√£o de um Sujeito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611724d2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Plotar primeiros 10 segundos do sujeito 01\n",
    "subj = subjects[0]\n",
    "t = np.arange(len(subj['ppg'])) / subj['fs']\n",
    "end_idx = int(10 * subj['fs'])\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6), sharex=True)\n",
    "\n",
    "axes[0].plot(t[:end_idx], subj['ecg'][:end_idx], 'b-', linewidth=0.8)\n",
    "axes[0].set_ylabel('ECG (Lead II)')\n",
    "axes[0].set_title(f\"üìä Sujeito {subj['id']} - Primeiros 10 segundos\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(t[:end_idx], subj['ppg'][:end_idx], 'purple', linewidth=0.8)\n",
    "axes[1].set_ylabel('PPG (PLETH)')\n",
    "axes[1].set_xlabel('Tempo (s)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77494654",
   "metadata": {},
   "source": [
    "## 3. Detectando Picos e Criando Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cdae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ecg_r_peaks(ecg, fs, min_distance_sec=0.4):\n",
    "    \"\"\"\n",
    "    Detecta picos R no ECG usando derivada + threshold.\n",
    "    \"\"\"\n",
    "    # Filtro passa-banda para QRS (5-25 Hz)\n",
    "    nyq = fs / 2\n",
    "    b, a = butter(2, [5/nyq, 25/nyq], btype='band')\n",
    "    ecg_filt = filtfilt(b, a, ecg)\n",
    "    \n",
    "    # Elevar ao quadrado\n",
    "    ecg_sq = ecg_filt ** 2\n",
    "    \n",
    "    # Suavizar\n",
    "    ecg_smooth = gaussian_filter1d(ecg_sq, sigma=fs * 0.02)\n",
    "    \n",
    "    # Detectar picos\n",
    "    min_dist = int(min_distance_sec * fs)\n",
    "    threshold = np.percentile(ecg_smooth, 70)\n",
    "    peaks, _ = find_peaks(ecg_smooth, distance=min_dist, height=threshold)\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "\n",
    "def transfer_peaks_to_ppg(ecg_peaks, ppg, fs, ptt_range=(0.15, 0.35)):\n",
    "    \"\"\"\n",
    "    Transfere picos R do ECG para picos sist√≥licos do PPG.\n",
    "    O Pulse Transit Time (PTT) √© tipicamente 150-350ms.\n",
    "    \"\"\"\n",
    "    ppg_peaks = []\n",
    "    ptt_min = int(ptt_range[0] * fs)\n",
    "    ptt_max = int(ptt_range[1] * fs)\n",
    "    \n",
    "    for ecg_peak in ecg_peaks:\n",
    "        search_start = ecg_peak + ptt_min\n",
    "        search_end = ecg_peak + ptt_max\n",
    "        \n",
    "        if search_end >= len(ppg):\n",
    "            continue\n",
    "        \n",
    "        # M√°ximo local na janela\n",
    "        window = ppg[search_start:search_end]\n",
    "        local_max = np.argmax(window)\n",
    "        ppg_peaks.append(search_start + local_max)\n",
    "    \n",
    "    return np.array(ppg_peaks)\n",
    "\n",
    "\n",
    "def create_labels_for_subject(subject):\n",
    "    \"\"\"\n",
    "    Cria labels bin√°rios para um sujeito.\n",
    "    \"\"\"\n",
    "    ppg = subject['ppg']\n",
    "    ecg = subject['ecg']\n",
    "    fs = subject['fs']\n",
    "    \n",
    "    # Detectar picos R no ECG\n",
    "    ecg_peaks = detect_ecg_r_peaks(ecg, fs)\n",
    "    \n",
    "    # Transferir para PPG\n",
    "    ppg_peaks = transfer_peaks_to_ppg(ecg_peaks, ppg, fs)\n",
    "    \n",
    "    # Criar array de labels\n",
    "    labels = np.zeros(len(ppg))\n",
    "    for peak in ppg_peaks:\n",
    "        # Marcar regi√£o ¬±3 amostras (¬±24ms @ 125Hz)\n",
    "        for offset in range(-3, 4):\n",
    "            if 0 <= peak + offset < len(labels):\n",
    "                labels[peak + offset] = 1\n",
    "    \n",
    "    return ppg_peaks, labels\n",
    "\n",
    "\n",
    "# Processar todos os sujeitos\n",
    "print(\"üîç Detectando picos para todos os sujeitos...\")\n",
    "for subj in subjects:\n",
    "    ppg_peaks, labels = create_labels_for_subject(subj)\n",
    "    subj['peaks'] = ppg_peaks\n",
    "    subj['labels'] = labels\n",
    "    \n",
    "print(f\"‚úÖ Processados {len(subjects)} sujeitos\")\n",
    "\n",
    "# Estat√≠sticas de picos\n",
    "total_peaks = sum(len(s['peaks']) for s in subjects)\n",
    "print(f\"‚ù§Ô∏è Total de batimentos detectados: {total_peaks:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3acbe7",
   "metadata": {},
   "source": [
    "### Verifica√ß√£o Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709fdb49",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Plotar sujeito com picos detectados\n",
    "subj = subjects[5]  # Escolher outro sujeito\n",
    "start_sec, end_sec = 20, 30\n",
    "start_idx = int(start_sec * subj['fs'])\n",
    "end_idx = int(end_sec * subj['fs'])\n",
    "t = np.arange(len(subj['ppg'])) / subj['fs']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "ax.plot(t[start_idx:end_idx], subj['ppg'][start_idx:end_idx], 'purple', linewidth=1)\n",
    "\n",
    "# Marcar picos detectados\n",
    "peaks_in_range = subj['peaks'][(subj['peaks'] >= start_idx) & (subj['peaks'] < end_idx)]\n",
    "ax.scatter(t[peaks_in_range], subj['ppg'][peaks_in_range], \n",
    "           c='red', s=100, zorder=5, label='Picos Detectados')\n",
    "\n",
    "ax.set_xlabel('Tempo (s)')\n",
    "ax.set_ylabel('PPG')\n",
    "ax.set_title(f\"üéØ Sujeito {subj['id']} - Verifica√ß√£o de Detec√ß√£o de Picos\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fcfe22",
   "metadata": {},
   "source": [
    "## 4. Criando Dataset de Janelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(ppg, labels, window_size, stride):\n",
    "    \"\"\"\n",
    "    Cria janelas de PPG com labels correspondentes.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Normalizar PPG (Z-score por janela)\n",
    "    for start in range(0, len(ppg) - window_size, stride):\n",
    "        window_ppg = ppg[start:start + window_size].copy()\n",
    "        window_labels = labels[start:start + window_size].copy()\n",
    "        \n",
    "        # Z-score normaliza√ß√£o\n",
    "        mean = np.mean(window_ppg)\n",
    "        std = np.std(window_ppg) + 1e-8\n",
    "        window_ppg = (window_ppg - mean) / std\n",
    "        \n",
    "        # S√≥ incluir janelas com pelo menos 1 pico completo\n",
    "        if np.sum(window_labels) > 0:\n",
    "            X.append(window_ppg)\n",
    "            y.append(window_labels)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def prepare_dataset_loso(subjects, test_subject_id, window_size, stride):\n",
    "    \"\"\"\n",
    "    Prepara dataset para valida√ß√£o Leave-One-Subject-Out.\n",
    "    \n",
    "    Args:\n",
    "        subjects: Lista de todos os sujeitos\n",
    "        test_subject_id: ID do sujeito para teste\n",
    "        \n",
    "    Returns:\n",
    "        X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    X_train, y_train = [], []\n",
    "    X_test, y_test = [], []\n",
    "    \n",
    "    for subj in subjects:\n",
    "        X_subj, y_subj = create_windows(\n",
    "            subj['ppg'], subj['labels'], window_size, stride\n",
    "        )\n",
    "        \n",
    "        if subj['id'] == test_subject_id:\n",
    "            X_test.append(X_subj)\n",
    "            y_test.append(y_subj)\n",
    "        else:\n",
    "            X_train.append(X_subj)\n",
    "            y_train.append(y_subj)\n",
    "    \n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "    X_test = np.concatenate(X_test, axis=0) if X_test else np.array([])\n",
    "    y_test = np.concatenate(y_test, axis=0) if y_test else np.array([])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# Criar dataset completo primeiro (para treinamento r√°pido)\n",
    "print(\"üì¶ Criando janelas de treinamento...\")\n",
    "all_X, all_y = [], []\n",
    "for subj in subjects:\n",
    "    X_subj, y_subj = create_windows(subj['ppg'], subj['labels'], WINDOW_SIZE, STRIDE)\n",
    "    all_X.append(X_subj)\n",
    "    all_y.append(y_subj)\n",
    "\n",
    "X_all = np.concatenate(all_X, axis=0)\n",
    "y_all = np.concatenate(all_y, axis=0)\n",
    "\n",
    "print(f\"‚úÖ Dataset total: {X_all.shape[0]} janelas de {X_all.shape[1]} amostras\")\n",
    "\n",
    "# Split treino/valida√ß√£o (por agora, simples)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_all, y_all, test_size=0.15, random_state=42\n",
    ")\n",
    "print(f\"üîÄ Treino: {len(X_train)} | Valida√ß√£o: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436020b",
   "metadata": {},
   "source": [
    "## 5. Modelo Performer (Transformer com Aten√ß√£o Linear)\n",
    "\n",
    "O **Performer** usa FAVOR+ (Fast Attention Via positive Orthogonal Random features)\n",
    "para computar aten√ß√£o em O(n) ao inv√©s de O(n¬≤).\n",
    "\n",
    "Isso √© crucial para sinais longos como PPG @ 125Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46870fb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è Dispositivo: {device}\")\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Codifica√ß√£o posicional sinusoidal.\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class PerformerAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Aten√ß√£o Linear usando FAVOR+ (aproxima√ß√£o do softmax).\n",
    "    \n",
    "    Complexidade: O(n) ao inv√©s de O(n¬≤)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, n_heads=4, n_features=64):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        self.k_proj = nn.Linear(d_model, d_model)\n",
    "        self.v_proj = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Random features para aproxima√ß√£o do kernel\n",
    "        self.register_buffer(\n",
    "            'random_features',\n",
    "            torch.randn(n_heads, self.head_dim, n_features) / math.sqrt(n_features)\n",
    "        )\n",
    "    \n",
    "    def _feature_map(self, x):\n",
    "        \"\"\"Mapa de features positivas para aproximar exp(q¬∑k).\"\"\"\n",
    "        # x: (batch, heads, seq, head_dim)\n",
    "        # random_features: (heads, head_dim, n_features)\n",
    "        \n",
    "        # Proje√ß√£o random\n",
    "        x_proj = torch.einsum('bhsd,hdf->bhsf', x, self.random_features)\n",
    "        \n",
    "        # Softmax positivo (aproxima√ß√£o)\n",
    "        return F.softplus(x_proj)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, _ = x.shape\n",
    "        \n",
    "        # Proje√ß√µes Q, K, V\n",
    "        q = self.q_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.k_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.v_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Feature maps\n",
    "        q_prime = self._feature_map(q)  # (batch, heads, seq, n_features)\n",
    "        k_prime = self._feature_map(k)\n",
    "        \n",
    "        # Aten√ß√£o linear: O(n*d*m) onde m = n_features\n",
    "        # kv = k_prime^T @ v\n",
    "        kv = torch.einsum('bhsf,bhsd->bhfd', k_prime, v)  # (batch, heads, n_features, head_dim)\n",
    "        \n",
    "        # Denominador para normaliza√ß√£o\n",
    "        k_sum = k_prime.sum(dim=2, keepdim=True)  # (batch, heads, 1, n_features)\n",
    "        \n",
    "        # Numerador\n",
    "        qkv = torch.einsum('bhsf,bhfd->bhsd', q_prime, kv)  # (batch, heads, seq, head_dim)\n",
    "        \n",
    "        # Denominador por posi√ß√£o\n",
    "        denom = torch.einsum('bhsf,bhof->bhs', q_prime, k_sum) + 1e-8\n",
    "        \n",
    "        # Output normalizado\n",
    "        out = qkv / denom.unsqueeze(-1)\n",
    "        \n",
    "        # Reshape e proje√ß√£o final\n",
    "        out = out.transpose(1, 2).contiguous().view(batch, seq_len, self.d_model)\n",
    "        return self.out_proj(out)\n",
    "\n",
    "\n",
    "class PerformerBlock(nn.Module):\n",
    "    \"\"\"Bloco Transformer com Performer Attention.\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, n_heads=4, ff_dim=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = PerformerAttention(d_model, n_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Self-attention com residual\n",
    "        attn_out = self.attention(self.norm1(x))\n",
    "        x = x + self.dropout(attn_out)\n",
    "        \n",
    "        # Feed-forward com residual\n",
    "        ff_out = self.ff(self.norm2(x))\n",
    "        x = x + ff_out\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class PPGPeakPerformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo Performer para detec√ß√£o de picos em PPG.\n",
    "    \n",
    "    Arquitetura:\n",
    "    - Embedding 1D (Conv)\n",
    "    - Positional Encoding\n",
    "    - N x Performer Blocks\n",
    "    - Decoder (Conv 1D)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, window_size=500, d_model=64, n_heads=4, n_layers=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding: 1D signal -> d_model features\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv1d(1, d_model // 2, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(d_model // 2, d_model, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len=window_size)\n",
    "        \n",
    "        # Performer blocks\n",
    "        self.transformer = nn.ModuleList([\n",
    "            PerformerBlock(d_model, n_heads, ff_dim=d_model * 4, dropout=dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(d_model, d_model // 2, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(d_model // 2, 1, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, window_size)\n",
    "        batch, seq_len = x.shape\n",
    "        \n",
    "        # Embedding\n",
    "        x = x.unsqueeze(1)  # (batch, 1, seq_len)\n",
    "        x = self.embedding(x)  # (batch, d_model, seq_len)\n",
    "        x = x.transpose(1, 2)  # (batch, seq_len, d_model)\n",
    "        \n",
    "        # Positional encoding\n",
    "        x = self.pos_encoding(x)\n",
    "        \n",
    "        # Transformer blocks\n",
    "        for block in self.transformer:\n",
    "            x = block(x)\n",
    "        \n",
    "        # Decoder\n",
    "        x = x.transpose(1, 2)  # (batch, d_model, seq_len)\n",
    "        x = self.decoder(x)  # (batch, 1, seq_len)\n",
    "        \n",
    "        return x.squeeze(1)  # (batch, seq_len)\n",
    "\n",
    "\n",
    "# Criar modelo\n",
    "model = PPGPeakPerformer(\n",
    "    window_size=WINDOW_SIZE,\n",
    "    d_model=64,\n",
    "    n_heads=4,\n",
    "    n_layers=4,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"üèóÔ∏è Modelo Performer criado: {n_params:,} par√¢metros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3646eb",
   "metadata": {},
   "source": [
    "## 6. Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_performer(model, X_train, y_train, X_val, y_val, \n",
    "                   epochs=50, batch_size=64, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Treina o modelo Performer.\n",
    "    \"\"\"\n",
    "    # Tensors\n",
    "    X_train_t = torch.FloatTensor(X_train)\n",
    "    y_train_t = torch.FloatTensor(y_train)\n",
    "    X_val_t = torch.FloatTensor(X_val).to(device)\n",
    "    y_val_t = torch.FloatTensor(y_val).to(device)\n",
    "    \n",
    "    # DataLoader\n",
    "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Loss e optimizer\n",
    "    # Usar Focal Loss para lidar com desbalanceamento (poucos 1s, muitos 0s)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_f1': []}\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Valida√ß√£o\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_val_pred = model(X_val_t)\n",
    "            val_loss = criterion(y_val_pred, y_val_t).item()\n",
    "            \n",
    "            # F1 Score aproximado\n",
    "            y_pred_bin = (y_val_pred > 0.5).float()\n",
    "            tp = (y_pred_bin * y_val_t).sum()\n",
    "            fp = (y_pred_bin * (1 - y_val_t)).sum()\n",
    "            fn = ((1 - y_pred_bin) * y_val_t).sum()\n",
    "            precision = tp / (tp + fp + 1e-8)\n",
    "            recall = tp / (tp + fn + 1e-8)\n",
    "            f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "        \n",
    "        train_loss = np.mean(train_losses)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_f1'].append(f1.item())\n",
    "        \n",
    "        # Log\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d}/{epochs} | \"\n",
    "                  f\"Train: {train_loss:.4f} | Val: {val_loss:.4f} | F1: {f1:.4f}\")\n",
    "        \n",
    "        # Early save\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_performer.pth')\n",
    "    \n",
    "    # Carregar melhor modelo\n",
    "    model.load_state_dict(torch.load('best_performer.pth'))\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# Treinar\n",
    "print(\"üöÄ Iniciando treinamento do Performer...\")\n",
    "history = train_performer(model, X_train, y_train, X_val, y_val, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe7815",
   "metadata": {},
   "source": [
    "### Curvas de Aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Treino')\n",
    "axes[0].plot(history['val_loss'], label='Valida√ß√£o')\n",
    "axes[0].set_xlabel('√âpoca')\n",
    "axes[0].set_ylabel('Loss (BCE)')\n",
    "axes[0].set_title('üìâ Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history['val_f1'], color='green')\n",
    "axes[1].set_xlabel('√âpoca')\n",
    "axes[1].set_ylabel('F1 Score')\n",
    "axes[1].set_title('üéØ F1 Score na Valida√ß√£o')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef9fe03",
   "metadata": {},
   "source": [
    "## 7. Avalia√ß√£o Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e3c84",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Predi√ß√£o em algumas janelas de valida√ß√£o\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_sample = torch.FloatTensor(X_val[:8]).to(device)\n",
    "    y_pred = model(X_sample).cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "t_window = np.arange(WINDOW_SIZE) / FS\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(t_window, X_val[i], 'purple', alpha=0.7, linewidth=0.8, label='PPG')\n",
    "    ax.fill_between(t_window, y_val[i] * 0.5, alpha=0.3, color='green', label='Ground Truth')\n",
    "    ax.fill_between(t_window, y_pred[i] * 0.5, alpha=0.3, color='red', label='Predi√ß√£o')\n",
    "    ax.set_xlim([0, WINDOW_SEC])\n",
    "    ax.set_ylabel('PPG / Prob')\n",
    "    if i >= 6:\n",
    "        ax.set_xlabel('Tempo (s)')\n",
    "    if i == 0:\n",
    "        ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.suptitle('üéØ Performer: Predi√ß√£o vs Ground Truth', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff03718",
   "metadata": {},
   "source": [
    "## 8. Infer√™ncia nos Seus Dados (ESP32)\n",
    "\n",
    "Carregue um arquivo do seu ESP32, decime para 125Hz, e rode o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_esp32_and_predict(model, filepath, original_fs=757, target_fs=125):\n",
    "    \"\"\"\n",
    "    Carrega dados do ESP32, decima, e prediz picos.\n",
    "    \"\"\"\n",
    "    # Carregar dados\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if 'ir_waveform' in df.columns:\n",
    "            ppg = df['ir_waveform'].values\n",
    "        elif 'IR' in df.columns:\n",
    "            ppg = df['IR'].values\n",
    "        else:\n",
    "            ppg = df.iloc[:, 0].values\n",
    "        print(f\"‚úÖ Carregado: {len(ppg)} amostras @ {original_fs}Hz\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro ao carregar: {e}\")\n",
    "        print(\"   Usando dado sint√©tico do BIDMC para demonstra√ß√£o...\")\n",
    "        ppg = subjects[10]['ppg'][:original_fs * 30]  # 30 segundos\n",
    "        original_fs = 125  # J√° est√° em 125Hz\n",
    "    \n",
    "    # Decimar se necess√°rio\n",
    "    if original_fs != target_fs:\n",
    "        n_samples = int(len(ppg) * target_fs / original_fs)\n",
    "        ppg_resampled = resample(ppg, n_samples)\n",
    "        print(f\"üìâ Decimado para {target_fs}Hz: {len(ppg_resampled)} amostras\")\n",
    "    else:\n",
    "        ppg_resampled = ppg\n",
    "    \n",
    "    # Predi√ß√£o com janelas sobrepostas\n",
    "    window_size = WINDOW_SIZE\n",
    "    stride = window_size // 4\n",
    "    \n",
    "    predictions = np.zeros(len(ppg_resampled))\n",
    "    counts = np.zeros(len(ppg_resampled))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, len(ppg_resampled) - window_size, stride):\n",
    "            window = ppg_resampled[start:start + window_size]\n",
    "            \n",
    "            # Normalizar\n",
    "            window_norm = (window - np.mean(window)) / (np.std(window) + 1e-8)\n",
    "            \n",
    "            # Predizer\n",
    "            window_t = torch.FloatTensor(window_norm).unsqueeze(0).to(device)\n",
    "            pred = model(window_t).cpu().numpy().squeeze()\n",
    "            \n",
    "            predictions[start:start + window_size] += pred\n",
    "            counts[start:start + window_size] += 1\n",
    "    \n",
    "    # M√©dia das predi√ß√µes sobrepostas\n",
    "    predictions = predictions / np.maximum(counts, 1)\n",
    "    \n",
    "    # Encontrar picos\n",
    "    peaks, _ = find_peaks(predictions, height=0.5, distance=int(0.4 * target_fs))\n",
    "    \n",
    "    return ppg_resampled, predictions, peaks\n",
    "\n",
    "\n",
    "# Testar com um arquivo ESP32 ou usar dado BIDMC\n",
    "esp32_path = os.path.join(ESP32_DIR, 'sample.csv')  # Ajuste para seu arquivo\n",
    "\n",
    "ppg_esp32, probs, detected_peaks = load_esp32_and_predict(model, esp32_path)\n",
    "\n",
    "# Calcular HR\n",
    "if len(detected_peaks) > 1:\n",
    "    rr = np.diff(detected_peaks) / FS * 1000  # ms\n",
    "    hr = 60000 / np.mean(rr)\n",
    "    sdnn = np.std(rr)\n",
    "    print(f\"\\n‚ù§Ô∏è HR: {hr:.1f} BPM | SDNN: {sdnn:.1f} ms | {len(detected_peaks)} picos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af55f578",
   "metadata": {},
   "source": [
    "### Visualiza√ß√£o da Infer√™ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(len(ppg_esp32)) / FS\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6), sharex=True)\n",
    "\n",
    "# PPG com picos\n",
    "axes[0].plot(t, ppg_esp32, 'purple', linewidth=0.8)\n",
    "axes[0].scatter(t[detected_peaks], ppg_esp32[detected_peaks], \n",
    "                c='red', s=80, zorder=5, label='Picos Detectados')\n",
    "axes[0].set_ylabel('PPG')\n",
    "axes[0].set_title('üéØ Infer√™ncia Performer no Sinal ESP32')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Probabilidades\n",
    "axes[1].plot(t, probs, 'orange', linewidth=0.8)\n",
    "axes[1].axhline(0.5, color='red', linestyle='--', alpha=0.5, label='Threshold')\n",
    "axes[1].set_ylabel('P(pico)')\n",
    "axes[1].set_xlabel('Tempo (s)')\n",
    "axes[1].set_ylim(-0.05, 1.05)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aeb46a",
   "metadata": {},
   "source": [
    "## 9. Salvar Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49965b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/douglas/Documentos/Projects/PPG/pulse-analytics/analytics/performer_peak_detector.pth'\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': {\n",
    "        'window_size': WINDOW_SIZE,\n",
    "        'target_fs': FS,\n",
    "        'd_model': 64,\n",
    "        'n_heads': 4,\n",
    "        'n_layers': 4\n",
    "    }\n",
    "}, save_path)\n",
    "\n",
    "print(f\"üíæ Modelo salvo em: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba3e9a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## üéì Resumo\n",
    "\n",
    "| Etapa | O que fizemos |\n",
    "|-------|---------------|\n",
    "| **1. Dados** | Carregamos 53 sujeitos BIDMC (PPG + ECG @ 125Hz) |\n",
    "| **2. Labels** | Detectamos pico R no ECG ‚Üí transferimos para PPG (PTT ~200ms) |\n",
    "| **3. Janelas** | Criamos janelas de 4s com labels bin√°rios |\n",
    "| **4. Modelo** | Performer (Transformer com aten√ß√£o O(n)) |\n",
    "| **5. Treino** | BCE Loss + AdamW + Cosine Annealing |\n",
    "| **6. Infer√™ncia** | Predi√ß√£o com overlap ‚Üí find_peaks ‚Üí RR intervals |\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "- [ ] Valida√ß√£o LOSO completa (53 folds)\n",
    "- [ ] Fine-tuning com seus dados ESP32\n",
    "- [ ] Exportar para ONNX / TensorFlow Lite\n",
    "- [ ] Deploy no ESP32 (Micro)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
